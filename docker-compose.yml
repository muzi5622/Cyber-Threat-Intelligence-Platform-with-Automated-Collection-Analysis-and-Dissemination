services:
  # =========================================================
  # LAYER 1 — Core dependencies required by OpenCTI
  # =========================================================

  redis:
    # Used by OpenCTI for caching + internal queues
    image: redis:7
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 10

  elasticsearch:
    # Stores OpenCTI data (search + indexing)
    image: docker.elastic.co/elasticsearch/elasticsearch:8.13.4
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - xpack.ml.enabled=false
      - ES_JAVA_OPTS=-Xms1g -Xmx1g
    ulimits:
      memlock: { soft: -1, hard: -1 }
      nofile: { soft: 65536, hard: 65536 }
    volumes:
      - esdata:/usr/share/elasticsearch/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:9200 >/dev/null || exit 1"]
      interval: 15s
      timeout: 5s
      retries: 30

  minio:
    # Object storage used by OpenCTI (imports/exports/attachments)
    image: minio/minio:RELEASE.2025-01-20T14-49-07Z
    command: server /data
    environment:
      - MINIO_ROOT_USER=${MINIO_USER}
      - MINIO_ROOT_PASSWORD=${MINIO_PASS}
    volumes:
      - miniodata:/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:9000/minio/health/live >/dev/null || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 20

  rabbitmq:
    # Message broker used by OpenCTI + worker/connectors (job distribution)
    image: rabbitmq:3-management
    environment:
      - RABBITMQ_DEFAULT_USER=${RABBITMQ_USER}
      - RABBITMQ_DEFAULT_PASS=${RABBITMQ_PASS}
    ports:
      - "15672:15672"
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "rabbitmq-diagnostics -q ping"]
      interval: 10s
      timeout: 5s
      retries: 20


  # =========================================================
  # LAYER 2 — OpenCTI platform + worker
  # =========================================================

  opencti:
    # Main OpenCTI web app + GraphQL API
    image: opencti/platform:latest
    environment:
      - APP__PORT=8080
      - APP__BASE_URL=${APP_BASE_URL}
      - APP__ADMIN__EMAIL=${OPENCTI_ADMIN_EMAIL}
      - APP__ADMIN__PASSWORD=${OPENCTI_ADMIN_PASSWORD}
      - APP__ADMIN__TOKEN=${OPENCTI_ADMIN_TOKEN}
      - APP__LOGS_LEVEL=info
      - APP__ENCRYPTION_KEY=${APP_ENCRYPTION_KEY}
      # Dependencies
      - REDIS__HOSTNAME=redis
      - ELASTICSEARCH__URL=http://elasticsearch:9200
      - MINIO__ENDPOINT=minio
      - MINIO__PORT=9000
      - MINIO__ACCESS_KEY=${MINIO_USER}
      - MINIO__SECRET_KEY=${MINIO_PASS}
      - RABBITMQ__HOSTNAME=rabbitmq
      - RABBITMQ__PORT=5672
      - RABBITMQ__USERNAME=${RABBITMQ_USER}
      - RABBITMQ__PASSWORD=${RABBITMQ_PASS}
    depends_on:
      - redis
      - elasticsearch
      - minio
      - rabbitmq
    ports:
      - "8080:8080"
    restart: unless-stopped

    # Health validation of GraphQL
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "python3 - <<'PY'\nimport os, json, urllib.request\nurl='http://localhost:8080/graphql'\ntoken=os.environ.get('APP__ADMIN__TOKEN','')\npayload={'query':'query { about { version } }'}\nheaders={'Content-Type':'application/json','Authorization':f'Bearer {token}'}\nreq=urllib.request.Request(url, data=json.dumps(payload).encode(), headers=headers)\nurllib.request.urlopen(req, timeout=5).read()\nprint('ok')\nPY"
        ]
      interval: 15s
      timeout: 10s
      retries: 40

  worker:
    # Processes background tasks
    image: opencti/worker:latest
    environment:
      - OPENCTI_URL=http://opencti:8080
      - OPENCTI_TOKEN=${OPENCTI_ADMIN_TOKEN}
      - WORKER_LOG_LEVEL=info
    depends_on:
      - opencti
    restart: unless-stopped


  # =========================================================
  # LAYER 3 — Ingestion & Enrichment
  # =========================================================

  rss-ingestor:
    build: ./services/rss-ingestor
    environment:
      OPENCTI_BASE: "http://opencti:8080"
      OPENCTI_TOKEN: "${OPENCTI_ADMIN_TOKEN}"
      RUN_EVERY_SECONDS: "300"
      RSS_STATE_DB: "/state/rss.db"
    volumes:
      - ./data/rss:/state
    depends_on:
      - opencti
    restart: unless-stopped

  connector-urlhaus:
    image: opencti/connector-urlhaus:rolling
    cpus: "0.10"
    mem_limit: 384m
    environment:
      - OPENCTI_URL=http://opencti:8080
      - OPENCTI_TOKEN=${OPENCTI_ADMIN_TOKEN}
      - CONNECTOR_ID=${CONNECTOR_URLHAUS_ID}
      - CONNECTOR_TYPE=EXTERNAL_IMPORT
      - CONNECTOR_NAME=URLHaus
      - CONNECTOR_SCOPE=urlhaus
      - CONNECTOR_DURATION_PERIOD=P1D
    depends_on:
      - opencti
      - rabbitmq
    restart: unless-stopped

  connector-alienvault:
    image: opencti/connector-alienvault:6.9.13
    environment:
      - OPENCTI_URL=http://opencti:8080
      - OPENCTI_TOKEN=${OPENCTI_ADMIN_TOKEN}
      - CONNECTOR_ID=${CONNECTOR_ALIENVAULT_ID}
      - ALIENVAULT_API_KEY=${OTX_API_KEY}
      - ALIENVAULT_PULSE_START_TIMESTAMP=2026-02-20T00:00:00
      - CONNECTOR_DURATION_PERIOD=PT12H
      # Optional additional limits
      - ALIENVAULT_REPORT_TYPE=PULSE
      - CONNECTOR_UPDATE_EXISTING_DATA=false
    depends_on:
      opencti:
        condition: service_healthy
    restart: unless-stopped

  nlp-enricher:
    build: ./services/nlp-enricher
    environment:
      OPENCTI_BASE: "http://opencti:8080"
      OPENCTI_TOKEN: "${OPENCTI_ADMIN_TOKEN}"
      RUN_EVERY_SECONDS: "120"
      NLP_STATE_DB: "/state/nlp.db"
    volumes:
      - ./data/nlp:/state
    depends_on:
      - opencti
    restart: unless-stopped

  ml-ner-enricher:
    build: ./services/ml-ner-enricher
    environment:
      - OPENCTI_BASE=http://opencti:8080
      - OPENCTI_TOKEN=${OPENCTI_ADMIN_TOKEN}
      - STATE_PATH=/data/state.json
      - MODEL_PATH=muzi5622/cti-ner-model
    volumes:
      - ./data/ml:/data
      - ./models_cache:/root/.cache/huggingface/transformers
    depends_on:
      - opencti
    restart: unless-stopped


  actor-profiler:
    build: ./services/actor-profiler
    environment:
      - ES_URL=http://elasticsearch:9200
      - ES_INDEX=honeypot-logs-*
      - OPENCTI_URL=http://opencti:8080
      - OPENCTI_TOKEN=${OPENCTI_ADMIN_TOKEN}
      - RUN_EVERY_SECONDS=300
      - LOOKBACK_MINUTES=60

      # Hugging Face model repo
      - HF_REPO_ID=muzi5622/actor-profiler-model
      # Optional if repo is private:
      # - HF_TOKEN=${HF_TOKEN}

      # Optional state db for checkpointing
      - STATE_PATH=/state/state.json
    volumes:
      - ./services/actor-profiler/app.py:/app/app.py:ro
      - ./data/actor-profiler:/state
    depends_on:
      - elasticsearch
      - opencti
    restart: unless-stopped

  intel-api:
    build: ./services/intel-api
    environment:
      - OPENCTI_BASE=http://opencti:8080
      - OPENCTI_TOKEN=${OPENCTI_ADMIN_TOKEN}
    ports:
      - "8000:8000"
    depends_on:
      - opencti
    restart: unless-stopped

  connector-mitre:
    image: opencti/connector-mitre:latest
    environment:
      - OPENCTI_URL=http://opencti:8080
      - OPENCTI_TOKEN=${OPENCTI_ADMIN_TOKEN}
      - CONNECTOR_ID=${CONNECTOR_MITRE_ID}
    depends_on:
      - opencti
    restart: unless-stopped

  logstash:
    image: docker.elastic.co/logstash/logstash:8.13.4
    depends_on:
      - elasticsearch
    ports:
      - "5044:5044" 
      - "9001:9001/tcp"
      - "5514:5514/udp"
    volumes:
      - ./logstash/pipeline:/usr/share/logstash/pipeline:ro
    environment:
      - xpack.monitoring.enabled=false
    restart: unless-stopped
  kibana:
    image: docker.elastic.co/kibana/kibana:8.13.4
    depends_on:
      - elasticsearch
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
      - "5601:5601"
    restart: unless-stopped
  # =========================================================
  # LAYER 4 — Dissemination (TAXII)
  # =========================================================
  # =========================================================
  # LAYER 4 — Dissemination (OpenCTI → STIX bundles on disk → served via Sharing Gateway)
  # =========================================================
  taxii-exporter:
    build: ./services/taxii-exporter
    environment:
      - OPENCTI_BASE=http://opencti:8080
      - OPENCTI_TOKEN=${OPENCTI_ADMIN_TOKEN}
      - EXPORT_DIR=/exports
      - RUN_EVERY_SECONDS=300
      - SHARE_POLICY_PATH=/app/policies/partners.yml
      - EXPORT_PARTNER_NAME=bank
    volumes:
      - ./data/opencti-export:/exports
      - ./services/taxii-exporter/policies:/app/policies:ro
    depends_on:
      - opencti
    restart: unless-stopped

  taxii-server:
    build:
      context: ./services/taxii-exporter/medallion
    environment:
      - TAXII_HOST=0.0.0.0
      - TAXII_PORT=9000
      - PARTNER_API_KEY=${PARTNER_API_KEY:-BANK123}
      - INTERNAL_API_KEY=${INTERNAL_API_KEY:-INTERNAL123}
    ports:
      - "9000:9000"
    volumes:
      - ./data/opencti-export:/data
    restart: unless-stopped
volumes:
  esdata:
  miniodata:
